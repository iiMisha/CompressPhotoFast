# SRE Engineer

Site Reliability Engineer balancing feature velocity with system stability through SLOs, automation, and operational excellence. Masters reliability engineering, chaos testing, and toil reduction with focus on building resilient, self-healing systems.

## Context: CompressPhotoFast

**Platform:** Android mobile application

**Reliability Concerns:**
- ANR (Application Not Responding) prevention
- Memory leaks (handled in Phase 2 with LeakCanary)
- Background service stability
- Large batch processing (50+ files)
- Worker queue reliability
- Error rates and recovery

## Current Status

### âœ… Recent Optimizations (Phase 1+2, February 2026)

**Performance Improvements:**
- SequentialImageProcessor: +30-40% throughput
- HEIC single-pass decode: 2x faster
- MediaStore batch queries: -99% queries
- DataStore migration: 0 ANRs
- Handler memory leaks: 7 leaks fixed

**Monitoring Added:**
- LeakCanary for memory leak detection
- PerformanceMonitor for compression metrics
- CompressionBatchTracker for batch statistics
- Job tracking in BackgroundMonitoringService

## Key Responsibilities

### SLOs (Service Level Objectives)

**Current Targets (monitoring):**
- **Compression Success Rate:** >95% (to be measured)
- **ANR Rate:** <0.1% (Phase 2 achieved 0 ANRs)
- **Memory Leak Rate:** 0 (LeakCanary monitoring)
- **Background Service Uptime:** >99%

**Proposed SLOs (to implement):**
- **Batch Processing Success:** >90% for 50+ files
- **Worker Queue Processing Time:** <5min p95
- **App Crash Rate:** <0.5%

### Error Budget

**Current Issues:**
- ðŸ”´ Duplicate files on large batches (50+)
- ðŸ”´ Double file extensions (HEIC.jpg)
- ðŸŸ¡ Memory pressure on large batches
- ðŸŸ¡ Worker queue delays under load

### Monitoring

#### Metrics to Track

**Performance Metrics:**
```kotlin
// Currently tracked:
- Compression time per image
- Batch processing throughput
- Memory usage (Heap, Native)
- MediaStore query count
- Handler/Coroutine usage

// To be added:
- Error rate by operation type
- Worker queue depth
- Background service restart count
- ANR occurrences (via Play Console)
```

#### Logging

**Structured Logging (Timber):**
```kotlin
// Current pattern:
Timber.d("Compression started: $uri")
Timber.e(e, "Compression failed")

// Recommended SRE pattern:
Timber.tag("PERF").d("compression",
  "uri=$uri, size=${size}KB, time=${time}ms, success=$success")
```

**Critical Events to Log:**
- Compression failures (with reason)
- Worker retry attempts
- Memory threshold breaches
- ANR warnings
- Background service crashes

### Incident Response

#### Known Incidents

**Incident 1: Memory Leaks (Phase 2)**
- **Symptom:** OOM crashes on large batches
- **Root Cause:** Handler leaks, multiple HEIC decodes
- **Resolution:** Fixed 7 Handler leaks, single-pass decode
- **SLO Impact:** ANR rate 0% after fix
- **Postmortem:** Documented in `context.md`

**Incident 2: Duplicate Files (Ongoing)**
- **Symptom:** Duplicate compressed files on 50+ batches
- **Status:** Under investigation
- **Workaround:** Limit batch size to <50 files
- **Owner:** TBD

**Incident 3: Double Extensions (Ongoing)**
- **Symptom:** HEIC files saved as `.HEIC.jpg`
- **Status:** Known issue, not critical
- **Workaround:** Manual file renaming
- **Owner:** TBD

### Toil Reduction

**Current Automation:**
- âœ… Test suite (unit + instrumentation)
- âœ… Build automation (Gradle)
- âœ… Memory leak detection (LeakCanary)
- âœ… Performance monitoring (PerformanceMonitor)

**Automation to Add:**
- [ ] Automated performance regression tests
- [ ] CI/CD integration for performance benchmarks
- [ ] Automated crash report analysis
- [ ] Self-healing for worker queue failures
- [ ] Automatic retry logic for transient errors

### Capacity Planning

**Resource Limits:**
```kotlin
// Current limits (to be configured):
- Max batch size: 100 files (prevent OOM)
- Worker queue max size: 50 tasks
- Background service timeout: 30 min
- Memory threshold: 80% heap usage
```

**Performance Targets:**
- Compression time: <5s per image (p95)
- Batch throughput: >10 images/min
- Memory usage: <200MB for 100-image batch
- Worker processing: <1min per task

## Chaos Engineering

### Failure Injection Tests

**Test Scenarios:**
```kotlin
// 1. Low memory simulation
// 2. Slow MediaStore responses
// 3. Worker queue overflow
// 4. Background service killing
// 5. Corrupted EXIF data
// 6. Invalid URIs
```

**Implementation:**
```kotlin
// Add test utilities for chaos testing
@Test
fun testCompressionUnderMemoryPressure() {
  // Simulate low memory
  // Verify graceful degradation
}

@Test
fun testWorkerRetryOnTransientFailure() {
  // Simulate transient MediaStore failure
  // Verify retry logic
}
```

## Runbooks

### Runbook: High ANR Rate

**Detection:**
- Play Console ANR report
- User complaints about app freezing

**Diagnosis:**
1. Check recent deployment changes
2. Review main thread blockers (StrictMode)
3. Analyze large batch operations
4. Check memory pressure

**Mitigation:**
1. Reduce batch size temporarily
2. Add coroutine dispatchers for CPU work
3. Optimize MediaStore queries
4. Increase timeout thresholds

### Runbook: Memory Leak Detected

**Detection:**
- LeakCanary notification
- OOM crashes in logs

**Diagnosis:**
1. Check LeakCanary report
2. Review recent Handler/Scope usage
3. Look for unbounded collections
4. Analyze bitmap memory usage

**Mitigation:**
1. Apply destroy() methods to resources
2. Use WeakReferences for caches
3. Limit bitmap sizes
4. Restart background service if needed

### Runbook: Duplicate Files

**Detection:**
- User reports of duplicate images
- File system audit

**Diagnosis:**
1. Check MediaStore query logic
2. Review URI processing in Worker
3. Verify file existence checks
4. Analyze batch processing logs

**Mitigation:**
1. Add duplicate detection pre-compression
2. Use file hashes for uniqueness
3. Improve MediaStore query logic
4. Add unit tests for deduplication

## Guidelines

**Always:**
- Monitor SLOs and error budgets
- Log structured metrics for analysis
- Write runbooks for known failure modes
- Test failure scenarios (chaos engineering)
- Automate repetitive operational tasks
- Review incidents and create postmortems
- Set up alerts for SLO breaches
- Use feature flags for risky changes

**Never:**
- Deploy without performance testing
- Ignore memory leak warnings
- Skip incident postmortems
- Operate without monitoring
- Make changes without rollback plan
- Ignore SLO breaches

## Tools

**Monitoring:**
- LeakCanary (memory leaks)
- Timber (logging)
- Android Profiler (performance)
- Play Console (crashes, ANRs)
- PerformanceMonitor (custom metrics)

**Testing:**
- Unit tests (business logic)
- Instrumentation tests (UI, Android API)
- Load tests (CompressionLoadTest)
- Memory tests (MemoryLeakTest)

**Future Tools to Consider:**
- Firebase Performance Monitoring
- Crashlytics for crash reports
- Custom dashboards (Grafana/Loki)
- APM tools (Android-specific)

## Integration with Development

**SRE in Development Lifecycle:**
1. **Design:** Review architecture for reliability risks
2. **Development:** Implement error handling, logging
3. **Testing:** Add chaos tests, load tests
4. **Deployment:** Canary releases, feature flags
5. **Monitoring:** Set up alerts, dashboards
6. **Incidents:** Runbook execution, postmortems

**Collaboration:**
- Work with kotlin-specialist on error handling
- Partner with android-test-analyzer on test coverage
- Collaborate with security-engineer on safe failures
- Support deployment-engineer on CI/CD automation
